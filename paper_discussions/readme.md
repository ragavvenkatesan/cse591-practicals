### Optimization / Training Techniques

| Id | Schedule | Presenters | Paper(s) | Link(s) | 
|----|----------|-----------|----------|---------|
| 1. |  |  | Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), S. Loffe and C. Szegedy | [[pdf]](http://arxiv.org/pdf/1502.03167) |
| 2. |  |  | Adam: A method for stochastic optimization (2014), D. Kingma and J. Ba | [[pdf]](http://arxiv.org/pdf/1412.6980) |
| 3. |  |  | Layer Normalization (2016), J. Ba et al. | [[pdf]](https://arxiv.org/pdf/1607.06450v1.pdf) |
| 4. |  |  | Learning to learn by gradient descent by gradient descent (2016), M. Andrychowicz et al. | [[pdf]](http://arxiv.org/pdf/1606.04474v1) |
| 5. |  |  | Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models, S. Ioffe. | [[pdf]](https://arxiv.org/abs/1702.03275) |
| 6. |  |  | Understanding deep learning requires rethinking generalization, (2017) C. Zhang et al. | [[pdf]](https://arxiv.org/pdf/1611.03530) |
| 7. |  |  | Overcoming catastrophic forgetting in neural networks (2017) J Kirkpatrick et. al, | [[pdf]](https://arxiv.org/pdf/1612.00796.pdf) |
| 8. |  |  | An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks (2015) I. Goodfellow et. al, |  [[pdf]](https://arxiv.org/pdf/1312.6211.pdf) |


### Unsupervised / Generative Models
| Id | Schedule | Presenter | Paper(s) | Link(s) | 
|----|----------|-----------|----------|---------|
| 9. |  |  | Generative adversarial nets (2014), I. Goodfellow et al. | [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) |
| 10. |  |  | Improved techniques for training GANs (2016), T. Salimans et al. | [[pdf]](http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf) |
|     |  |  | Unsupervised representation learning with deep convolutional generative adversarial networks (2015), A. Radford et al. | [[pdf]](https://arxiv.org/pdf/1511.06434v2) |
| 11. |  |  | InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (2016), Xi Chen et. al, | [[pdf]](https://arxiv.org/pdf/1606.03657.pdf) |
|     |  |  | Learning from Simulated and Unsupervised Images through Adversarial Training (2016) Shrivatsava et al., | [[pdf]](https://arxiv.org/pdf/1612.07828.pdf) |
| 12. |  |  | Wasserstein GAN, M. Arjovsky et al. | [[pdf]](https://arxiv.org/pdf/1701.07875v1) |
| 13. |  |  | Energy-based Generative Adversarial Network (2016) Zhao et. al, | [[pdf]](https://arxiv.org/pdf/1609.03126.pdf) |


### Network Architecture
14. Identity Mappings in Deep Residual Networks (2016), K. He et al. [[pdf]](https://arxiv.org/pdf/1603.05027v2.pdf)
    Deep residual learning for image recognition (2016), K. He et al. [[pdf]](http://arxiv.org/pdf/1512.03385)
15. Deep networks with stochastic depth (2016), G. Huang et al., [[pdf]](https://arxiv.org/pdf/1603.09382)
16. Fully convolutional networks for semantic segmentation (2015), J. Long et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf) 
    Spatial transformer network (2015), M. Jaderberg et al., [[pdf]](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)
17. Semantic image segmentation with deep convolutional nets and fully connected CRFs, L. Chen et al. [[pdf]](https://arxiv.org/pdf/1412.7062)
18. Densely connected convolutional networks (2016), G. Huang et al. [[pdf]](https://arxiv.org/pdf/1608.06993v1)
    Transforming Autoencoders (2012), G. Hinton et al., [[pdf]](http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf)[[Thesis]](http://www.sidaw.xyz/pubs/wang2011trans-thesis.pdf)
19. Steerable CNNs (2017) T.S. Cohen et.al, [[pdf]](https://openreview.net/pdf?id=rJQKYt5ll)
20. Rethinking the inception architecture for computer vision (2016), C. Szegedy et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)
    Inception-v4, inception-resnet and the impact of residual connections on learning (2016), C. Szegedy et al. [[pdf]](http://arxiv.org/pdf/1602.07261)

## Network compression.
21. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015), S. Han et al. [[pdf]](https://arxiv.org/pdf/1510.00149)
22. Unifying distillation and priviliged information (2017) Lopez-paz et. al, [[pdf]](http://leon.bottou.org/publications/pdf/iclr-2016.pdf)
23. Optimal Brain Damage (1989) Y. LeCun et. al, [[pdf]] (http://yann.lecun.com/exdb/publis/pdf/lecun-90b.pdf)
24. On the Number of Linear Regions of Deep Neural Networks (2014) Mont√∫far, Guido et. al, [[pdf]](https://arxiv.org/pdf/1402.1869v2.pdf)
